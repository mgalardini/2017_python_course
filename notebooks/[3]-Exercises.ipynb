{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: solutions of the exercices of this lesson are at the end of this notebook\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "**Importing the package you will need on the top of your notebook is a good programming practice** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T15:08:05.694548",
     "start_time": "2017-09-18T15:08:05.389905Z"
    },
    "collapsed": true,
    "init_cell": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the packages that will be usefull for this part of the lesson\n",
    "from collections import OrderedDict, Counter\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Small trick to get a larger display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminder on file parsing strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Read the first line of the file and try to understand the structure and determine the length of the file**\n",
    "\n",
    "\n",
    "* **If the file is a standard genomic/proteomic format, read the documentation**\n",
    "\n",
    "\n",
    "* **Think about the most efficient way to parse the file to get the information you want**\n",
    "\n",
    "    * How are you going to access the field(s) of interest ? (you can test that with 1 line before starting with the whole file)\n",
    "    * A real life file will contain millions of lines and file reading is usually slow. Try to read the file only 1 time, even if you need to parse multiple element per line. \n",
    "    * How are you going to collect the information (dictionary, list, dataframe...) ?\n",
    "    \n",
    "**... Now you can parse the file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1: Randomly selected global event with catastrophic consequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T15:08:33.665644",
     "start_time": "2017-09-18T15:08:33.650204Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from random import choice\n",
    "disaster_list = [\"Global_pandemic\", \"Brexit\", \"US_presidential_elections\", \"Nuclear_war\", \"Asteroide_storm\", \"End of_antibiotics_era\"]\n",
    "choice(disaster_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-11T15:33:58.384552",
     "start_time": "2017-09-11T15:33:58.378502Z"
    }
   },
   "source": [
    "*The file indicated bellow contain a representative sample of popular votes for the last US presidential elections. Parse the file and return a count of the number of occurrence of each name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "file = \"../data/US_election_vote_sample.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2: Parsing a gene annotation file (gff3)**\n",
    "\n",
    "*Parse The following gff3 gene annotation file. Extract the **type** of each line and print the count ordered by descending occurrence*\n",
    "\n",
    "*gff3 is a standard genomic format. Read the [documentation here](http://gmod.org/wiki/GFF3).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "file = \"../data/gencode_sample.gff3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "! head -2 ../data/gencode_sample.gff3 # check format of GFF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# rearrange the lines below to create a working solution\n",
    "        type_field = line.split('\\t')[2]\n",
    "type_counter = Counter()\n",
    "    print('%s:\\t%d' % count_info)\n",
    "with open(file, 'r') as fh:\n",
    "    for line in fh.readlines():\n",
    "for count_info in type_counter.most_common():\n",
    "from collections import Counter\n",
    "        type_counter[type_field] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3: **\n",
    "\n",
    "*Parse The following gff3 gene annotation file. For each **seqid** (chromosome) list the sequences **ID** associated. Use an ordered dict to preserve the original chromosome ordering from the file*\n",
    "\n",
    "Example:\n",
    "\n",
    "    d={\"chr1\": [\"stop_codon:ENST00000370551.8\", \"UTR5:ENST00000235933.10\", ...], \"chr2\": [\"ID=CDS:ENST00000504764.5\", \"ID=UTR5:ENST00000480736.1\", ...], ... }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "file = \"../data/gencode_sample.gff3\"\n",
    "! head -2 ../data/gencode_sample.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# fill in the blanks (---) in the code below to create a working solution\n",
    "from collections import ---\n",
    "\n",
    "sequences = OrderedDict()\n",
    "\n",
    "with open(file, ---) as fh:\n",
    "    --- line in fh.readlines():\n",
    "        fields = line.split()\n",
    "        seqid = fields[---]\n",
    "        attributes = ---\n",
    "        ID = attributes.split(';')[0]\n",
    "        if --- in sequences:\n",
    "            sequences[seqid].append(ID)\n",
    "        else:\n",
    "            sequences[seqid] = [ID]\n",
    "\n",
    "for seq, ids in sequences.items():\n",
    "    print('%s:\\t%s' % (seq, ', '.join(ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4: **\n",
    "\n",
    "*1) Write a generator that can ouput DNA bases with the following frequencies A/T = 0.19 and  C/G = 0.31*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-11T16:33:27.353368",
     "start_time": "2017-09-11T16:33:27.322852Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Import the uniform method (which is also a generator by the way) to generate random floats\n",
    "from random import uniform\n",
    "\n",
    "def DNA_generator (): # Eventually you can have options for relative nucleotide frequencies\n",
    "        \n",
    "    # Calculate cummulative frequencies to avoid having to do it each time in the loop\n",
    "    ---\n",
    "    ---\n",
    "    ---\n",
    "    ---\n",
    "    \n",
    "    # Iterate indefinitly... until a nuclear apocalypse at least.\n",
    "    while True:\n",
    "        \n",
    "        # Generate a random float frequency between 0 and max freq\n",
    "        freq = uniform (0, ---)\n",
    "        \n",
    "        # Depending on the random frequency return the approriate base\n",
    "        if --- :\n",
    "            yield \"A\"\n",
    "        elif ---:\n",
    "            yield \"T\"\n",
    "        elif ---:\n",
    "            yield \"C\"\n",
    "        else:\n",
    "            yield \"G\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2) Using this generator to generate a 100nt sequence (as a string)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "d = DNA_generator()\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics and viewing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5: **\n",
    "\n",
    "*Parse The following sam file. *sam is a standard genomic format. Read the [documentation here](http://genome.sph.umich.edu/wiki/SAM). It can be read as a table with `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "file = \"../data/sample_alignment.sam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_table(file, comment='@', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following code blocks will:\n",
    "\n",
    "1) *Print the 10 last rows*?\n",
    "\n",
    "```Python\n",
    "# a)\n",
    "df.head(10)\n",
    "\n",
    "# b)\n",
    "df.tail(10)\n",
    "\n",
    "# c)\n",
    "df.last10()\n",
    "\n",
    "#d)\n",
    "df[6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) *Sample randomly 10 rows and compute the mean and median fragment length (TLEN)*?\n",
    "\n",
    "```Python\n",
    "# a)\n",
    "sample = df.sample(10)\n",
    "meanTLEN = sample[1].mean()\n",
    "medianTLEN = sample[1].median()\n",
    "\n",
    "# b)\n",
    "sample = df.sample(10)\n",
    "meanTLEN = sample[8].mean\n",
    "medianTLEN = sample[8].median\n",
    "\n",
    "# c)\n",
    "sample = df.sample(10)\n",
    "meanTLEN = sample[8].mean()\n",
    "medianTLEN = sample[8].median()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) *Generate a summary for all the columns*?\n",
    "\n",
    "```Python\n",
    "# a)\n",
    "pd.describe(df)\n",
    "\n",
    "# b)\n",
    "df.describe(include='all')\n",
    "\n",
    "# c)\n",
    "summarise(pd.df)\n",
    "\n",
    "# d)\n",
    "df.summarise('columns')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection and indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6: **\n",
    "\n",
    "*Parse the following count file obtained by Kallisto from an RNAseq Dataset. The file is not a standard genomics format, but it is a tabulated file and some information can be found in [Kallisto documentation](https://pachterlab.github.io/kallisto/manual.html).*\n",
    "\n",
    "1. *Extract the following **target_id**: 'ENST00000487368.4', 'ENST00000623229.1', 'ENST00000444276.1', 'ENST00000612487.4', 'ENST00000556673.2', 'ENST00000623191.1'*\n",
    "2. *Select only the **est_counts and tpm** columns and print the **first 10 lines** of the table*\n",
    "3. *Extract of the rows with a **tpm** value higher that 10000 *\n",
    "4. *Extract of the rows with a **tpm** and an **est_counts** higher than 1000, order by descending **eff_len** and print the **10 first lines**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "file = \"../data/abundance.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Merging dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T12:30:19.068500",
     "start_time": "2017-09-18T12:30:18.929469Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Exercise 7: **\n",
    "\n",
    "*1) Create a dataframe associating the abundance data from the abundance_file and the gene symbols from gene_to_transcript_file.*\n",
    "   \n",
    "* Do not include transcripts without gene symbols in the list\n",
    "* Sort the transcript_id\n",
    "* Reset the index\n",
    "* Discard the target_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "abundance_file = \"../data/abundance.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "gsym_to_tid_file = \"../data/gene_symbol_to_transcript_id.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T12:52:13.414961",
     "start_time": "2017-09-18T12:52:13.365374Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df1 = \n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T12:52:09.487817",
     "start_time": "2017-09-18T12:52:09.452207Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df2 = \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T12:59:26.489060",
     "start_time": "2017-09-18T12:59:26.414790Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df3 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing Pandas and generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7: **\n",
    "\n",
    "*Create a random codon generator based on the known codon usage bias in the human genome.*\n",
    "\n",
    "*The following file contains a list of all the human codon codons, their AA traduction, their count in the human genome and their frequency/1000: ```\"../data/codon_usage_bias_human.tsv\"```*\n",
    "\n",
    "*To do so, you can parse the file in a pandas DataFrame. Pandas has a very useful method to [sample](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html) a line from the Dataframe. Use the weights option to sample according to a  probability weighting.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-11T16:43:17.905515",
     "start_time": "2017-09-11T16:43:17.902657Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "file = \"../data/codon_usage_bias_human.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "# POSSIBLE ANSWERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "c = Counter()\n",
    "\n",
    "# Open the file\n",
    "with open (\"../data/US_election_vote_sample.txt\", \"r\") as fp:\n",
    "    for candidate in fp:\n",
    "        # Increment the counter for the current element\n",
    "        c[candidate]+=1\n",
    "\n",
    "# Order by most frequent element\n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "file = \"../data/gencode_sample.gff3\"\n",
    "c = Counter()\n",
    "\n",
    "# Open the file\n",
    "with open (file, \"r\") as fp:\n",
    "    # Iterate over lines\n",
    "    for line in fp:\n",
    "        # Split the line and get the element 3\n",
    "        feature_type = line.split(\"\\t\")[2]\n",
    "        # Increment the counter\n",
    "        c[feature_type]+=1\n",
    "        \n",
    "# Order by most frequent element\n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!head -n 1 \"../data/gencode_sample.gff3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "file = \"../data/gencode_sample.gff3\"\n",
    "d =  OrderedDict()\n",
    "\n",
    "# Open the file\n",
    "with open (file, \"r\") as fp:\n",
    "    # Iterate over lines\n",
    "    for line in fp:\n",
    "        # Split the line and get the element 3\n",
    "        seqid = line.split(\"\\t\")[0]\n",
    "        # Parse the line to get the ID\n",
    "        ID = line.split(\"\\t\")[8].split(\";\")[0][3:]\n",
    "        #\n",
    "        if not seqid in d:\n",
    "            d[seqid] = []\n",
    "        d[seqid].append(ID)\n",
    "        \n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ")1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "\n",
    "def DNA_generator (A_freq, T_freq, C_freq, G_freq): # Customizable frequency argument\n",
    "    \n",
    "    # Calculate cummulative frequencies to avoid having to do it each time in the loop\n",
    "    cum_A_freq = A_freq\n",
    "    cum_T_freq = A_freq+T_freq\n",
    "    cum_C_freq = A_freq+T_freq+C_freq\n",
    "    cum_G_freq = A_freq+T_freq+C_freq+G_freq\n",
    "    \n",
    "    # Iterate indefinitly\n",
    "    while True:\n",
    "        \n",
    "        # Generate a random float frequency between 0 and max freq\n",
    "        freq = uniform (0, cum_G_freq)\n",
    "        \n",
    "        # Depending on the random frequency return the approriate base\n",
    "        if freq <= cum_A_freq:\n",
    "            yield \"A\"\n",
    "        elif freq <= cum_T_freq:\n",
    "            yield \"T\"\n",
    "        elif freq <= cum_C_freq:\n",
    "            yield \"C\"\n",
    "        else:\n",
    "            yield \"G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# achieve the same using random.choices\n",
    "# if using python v<3.6, import choices from numpy.random\n",
    "\n",
    "from random import choices\n",
    "\n",
    "def DNA_generator_choices(weights=[0.19, 0.31, 0.31, 0.19], letters=['A', 'C', 'G', 'T']):\n",
    "    while True:\n",
    "        yield choices(population=letters, weights=weights, k=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the generator with the required frequencies\n",
    "d = DNA_generator(A_freq=0.19, T_freq=0.19, C_freq=0.31, G_freq=0.31)\n",
    "\n",
    "# Test the generator\n",
    "print(next(d), next(d), next(d), next(d), next(d), next(d), next(d), next(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the generator with the required frequencies\n",
    "d = DNA_generator_choices()\n",
    "\n",
    "# Test the generator\n",
    "print(next(d), next(d), next(d), next(d), next(d), next(d), next(d), next(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ")2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# iterative str contruction with a loop\n",
    "seq=\"\"\n",
    "for _ in range (100):\n",
    "    seq += next(d)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Same with a one liner list comprehension\n",
    "seq = \"\".join([next(d) for _ in range (100)])\n",
    "seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "file = \"../data/sample_alignment.sam\"\n",
    "columns_names = ['QNAME', 'FLAG', 'RNAME', 'POS', 'MAPQ', 'CIGAR', 'RNEXT', 'PNEXT', 'TLEN', 'SEQ', 'QUAL']\n",
    "df = pd.read_table(file, sep=\"\\t\", names = columns_names, skiprows=[0,1], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "tlen_sample = df.sample(10).TLEN\n",
    "print (tlen_sample)\n",
    "print (\"\\nMean:\", tlen_sample.mean())\n",
    "print (\"\\nMedian:\", tlen_sample.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "file = \"../data/abundance.tsv\"\n",
    "df = pd.read_table(file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df.loc[['ENST00000487368.4', 'ENST00000623229.1', 'ENST00000444276.1', 'ENST00000612487.4', 'ENST00000556673.2', 'ENST00000623191.1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df[[\"est_counts\", \"tpm\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df[(df.tpm > 10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df = df[(df.est_counts > 1000) & (df.tpm > 1000)]\n",
    "df = df.sort_values(\"eff_length\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T13:04:42.340745",
     "start_time": "2017-09-18T13:04:42.243007Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_table(\"../data/abundance.tsv\")\n",
    "df2 = pd.read_table(\"../data/gene_symbol_to_transcript_id.tsv\", names=[\"transcript_id\", \"gene_symbol\"])\n",
    "\n",
    "df3 = pd.merge(left=df1, right=df2, left_on=\"target_id\", right_on=\"transcript_id\", how=\"inner\")\n",
    "\n",
    "df3 = df3.sort_values(\"transcript_id\")\n",
    "df3 = df3.reset_index(drop=True)\n",
    "df3.drop([\"target_id\"], axis=1)\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T12:28:47.951682",
     "start_time": "2017-09-18T12:28:47.942664Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"\\x47\\x6f\\x6f\\x64 \\x4c\\x75\\x63\\x6b\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialisation Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
