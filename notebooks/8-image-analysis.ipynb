{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to BioImage Data Analysis with Python\n",
    "\n",
    "developed by *Jonas Hartmann (Gilmour group, EMBL Heidelberg)*<br>\n",
    "as part of the EMBL Bio-IT Course on [**Intermediate Python Programming**](https://bio-it.embl.de/events/intermediate-python-programming/)<br>\n",
    "20.09.2017\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "### Purpose\n",
    "\n",
    "This tutorial introduces a number of tools and strategies for image analysis (specifically fluorescence microscopy images as produced in the biosciences) available in python. It aims to give the course attendees a starting point to further explore image analysis packages and pipelines. Furthermore, it serves as another practical example of scientific python programming.\n",
    "\n",
    "\n",
    "### Format\n",
    "\n",
    "In the course, teacher and students develop the pipeline below together in an open session over the course of about two hours. The tutorial can also be used for self-study, which is best done by re-implementing, testing and playing around with each step of the pipeline.\n",
    "\n",
    "\n",
    "### Content\n",
    "\n",
    "The tutorial pipeline encompasses the following parts:\n",
    "\n",
    "1. Loading & viewing images\n",
    "2. Image processing & segmentation\n",
    "3. Data Extraction & analysis\n",
    "\n",
    "It is based on an example **3-channel image** of **human HT29 colon cancer cells** in culture, labeled with...\n",
    "\n",
    "- Hoechst stain (DNA)\n",
    "- Phalloidin (actin)\n",
    "- Histone H3 phosphorylated on serine 10 [pH3] antibody (mitosis marker)\n",
    "\n",
    "The example image was obtained from the [CellProfiler website](http://cellprofiler.org/examples/#HumanCells) and derives from [Moffat et al., 2006].\n",
    "\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "- python (2.7 or 3.x)\n",
    "- numpy, scipy, matplotlib\n",
    "- skimage, pandas, sklearn\n",
    "\n",
    "All packages used in this tutorial are part of the [Anaconda](https://www.anaconda.com/distribution/) distribution of python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading & Viewing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For python 2 users\n",
    "from __future__ import division, print_function \n",
    "\n",
    "# Scientific python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image analysis\n",
    "import scipy.ndimage as ndi\n",
    "from skimage import io, segmentation, graph, filters, measure\n",
    "\n",
    "# Machine learning\n",
    "from sklearn import preprocessing, svm, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Loading Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "raw = io.imread('../data/HT29.tif')\n",
    "\n",
    "# Check data structure and type\n",
    "print(type(raw))\n",
    "print(raw.shape)\n",
    "print(raw.dtype)\n",
    "print(raw.min(), raw.max(), raw.mean())\n",
    "\n",
    "# Split channels\n",
    "nuc = raw[:,:,0]\n",
    "pH3 = raw[:,:,1]\n",
    "act = raw[:,:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Viewing Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simple imshow\n",
    "plt.imshow(nuc, interpolation='none', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nice subplots\n",
    "fig,ax = plt.subplots(1, 3, figsize=(12,4))\n",
    "for axis,image,title in zip(ax, [nuc,pH3,act], ['Hoechst','pH3','Phalloidin']):\n",
    "    axis.imshow(image, interpolation='none', cmap='gray')\n",
    "    axis.set_title(title)\n",
    "    axis.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Colored overlay using rgb\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.imshow(np.zeros_like(nuc), vmax=1)    # Black background\n",
    "rgb = np.zeros(image.shape+(3,))          # Empty RGB\n",
    "for i,image in enumerate([act,pH3,nuc]):  # Add each channel to RGB\n",
    "    rgb[:,:,i] = (image.astype(np.float) - image.min()) / (image.max() - image.min()) # Normalize images to [0,1]\n",
    "plt.imshow(rgb, interpolation='none')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Processing & Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Preprocessing by Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smoothing an image to reduce technical noise is almost always the first step in image analysis. The most common smoothing algorithm is the **Gaussian filter**.\n",
    "\n",
    "The Gaussian filter is an example of a key technique of image analysis: **kernel convolution**. In image analysis, a **kernel** is a small 'mask' that is **moved over each pixel in the image**. At each pixel position, the kernel determines **which** of the surrounding pixels are used to compute the new value and **how much** each surrounding pixel contributes. Kernel convolutions can be implemented using Fast Fourier Transforms (FFTs), which makes them very fast.\n",
    "\n",
    "For the **Gaussian filter**, the kernel is a small Gaussian-like distribution (fig. 1). To compute a pixel of the smoothed image, the values of the surrounding pixels are multiplied by the corresponding kernel value, summed up, and normalized again (by dividing by the sum of kernel values). Thus, by 'diluting' the values of individual pixels with the values of neighboring pixels, a convolution with a Gaussian kernel leads to a smoothing of the image.\n",
    "\n",
    "<br><img src=\"..\\pictures\\gaussian_kernel_grid.png\" alt=\"Gaussian Filter Kernel\" style=\"width: 300px\">\n",
    "\n",
    "<center>**Fig 1:** Example of a Gaussian convolution kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gaussian smoothing\n",
    "nuc_smooth = ndi.gaussian_filter(nuc, sigma=1)\n",
    "\n",
    "# Show\n",
    "fig,ax = plt.subplots(1, 2, figsize=(12,12))\n",
    "ax[0].imshow(nuc, interpolation='none', cmap='gray')\n",
    "ax[0].set_title('Raw')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(nuc_smooth, interpolation='none', cmap='gray')\n",
    "ax[1].set_title('Smoothed')\n",
    "ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Simple Nucleus Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way of segmenting nuclei in these images is to combine **adaptive background subtraction** and **thresholding**.\n",
    "\n",
    "The idea of **adaptive background subtraction** is to compute a **local background** for each position of the image. If there is a slow continuous change in the image background, the local background can be adjusted for this, hence evening out the image.\n",
    "\n",
    "A simple way of computing the local background is a **convolution** with a relatively large **uniform (mean)** kernel (fig. 2). If this kernel is large compared to the structures in the image, the mean will usually end up lower than the foreground but higher than the background - perfect for background subtraction.\n",
    "\n",
    "<br><img src=\"..\\pictures\\uniform_kernel_grid.png\" alt=\"Uniform Filter Kernel\" style=\"width: 300px\">\n",
    "\n",
    "<center>**Fig 2:** Example of a circular uniform convolution kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adaptive background subtraction\n",
    "nuc_smooth_bg = ndi.uniform_filter(nuc_smooth, size=20)\n",
    "nuc_smooth_bgsub = nuc_smooth - nuc_smooth_bg\n",
    "nuc_smooth_bgsub[nuc_smooth < nuc_smooth_bg] = 0\n",
    "\n",
    "# Show\n",
    "fig,ax = plt.subplots(1, 2, figsize=(12,12))\n",
    "ax[0].imshow(nuc_smooth, interpolation='none', cmap='gray')\n",
    "ax[0].set_title('Smoothed')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(nuc_smooth_bgsub, interpolation='none', cmap='gray')\n",
    "ax[1].set_title('Background-subtracted')\n",
    "ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Interactive search for a good threshold\n",
    "\n",
    "# Plotting function\n",
    "def threshold_plot(threshold=10):\n",
    "    \n",
    "    # Threshold\n",
    "    nuc_mask = nuc_smooth_bgsub > threshold\n",
    "\n",
    "    # Show\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.imshow(nuc_smooth_bgsub, interpolation='none', cmap='gray')\n",
    "    plt.imshow(np.ma.array(nuc_mask, mask=nuc_mask==0), interpolation='none', cmap='autumn', alpha=0.5)\n",
    "    plt.axis('off')\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "# Interactive widget\n",
    "from ipywidgets import interactive\n",
    "interactive(threshold_plot, threshold=(1,255,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply threshold\n",
    "nuc_mask = nuc_smooth_bgsub > 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** There are a number of problems with a simple segmentation like this, namely the risk of **fused nuclei** and of **artefacts**, e.g. small debris or background fluctuations that are wrongly considered a nucleus. There are a number of ways to address these problems but for the purpose of this course we will consider the current result good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Label the image to give each object a unique number\n",
    "nuc_labeled = ndi.label(nuc_mask)[0]\n",
    "\n",
    "# Show\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.imshow(nuc_smooth_bgsub, interpolation='none', cmap='gray')\n",
    "plt.imshow(np.ma.array(nuc_labeled, mask=nuc_labeled==0), interpolation='none', cmap='prism', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Cell Segmentation by Watershed\n",
    "\n",
    "For many structures, simply filtering and thresholding the image is not enough to get a segmentation. In these cases, one of many alternatives must be applied.\n",
    "\n",
    "A very common approach is the **watershed** algorithm (fig. 3), which works by treating the image as a **topographical map** and slowly filling up the valleys in the map with water, starting from so-called **seeds**. Wherever the waterfronts of two different seeds meet, the boundary between these two objects is generated.\n",
    "\n",
    "Here we can use the **labeled nuclei** as seeds for a watershed segmentation of the cells based on the **phalloidin channel**.\n",
    "\n",
    "\n",
    "<br><img src=\"..\\pictures\\watershed_illustration.png\" alt=\"Watershed Explanation\" style=\"width: 900px\">\n",
    "\n",
    "<center>**Fig 3:** Graphical explanation of watershed segmentation.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify a background seed\n",
    "# Here, the 5th percentile on signal intensity is used.\n",
    "act_bgsub = act - np.percentile(act,5)\n",
    "act_bgsub[act < np.percentile(act,5)] = 0\n",
    "\n",
    "# Show\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.imshow(act, interpolation='none', cmap='gray')\n",
    "plt.imshow(np.ma.array(act_bgsub==0, mask=act_bgsub!=0), interpolation='none', cmap='autumn', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare the seeds\n",
    "seeds = np.copy(nuc_labeled)               # Cell seeds\n",
    "seeds[act_bgsub==0] = nuc_labeled.max()+1  # Add background seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the image by Sobel edge filtering\n",
    "act_sobel = filters.sobel(act_bgsub)\n",
    "\n",
    "# Show\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.imshow(act_sobel, interpolation='none', cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run watershed\n",
    "act_ws = segmentation.watershed(act_sobel, seeds)\n",
    "\n",
    "# Remove background\n",
    "act_ws[act_ws==nuc_labeled.max()+1] = 0\n",
    "\n",
    "# Show\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.imshow(act_bgsub, interpolation='none', cmap='gray')\n",
    "plt.imshow(np.ma.array(act_ws, mask=act_ws==0), interpolation='none', cmap='prism', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Better visualization\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "plt.imshow(act_bgsub, interpolation='none', cmap='gray')\n",
    "plt.imshow(np.ma.array(nuc_labeled, mask=nuc_labeled==0), interpolation='none', cmap='prism', alpha=0.3)\n",
    "boundaries = filters.sobel(act_ws) > 0 \n",
    "plt.imshow(np.ma.array(boundaries, mask=boundaries==0), interpolation='none', cmap='autumn', alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Extraction & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Extracting Region Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Regionprops provides a number of measurements per label\n",
    "nuc_props_nuc = measure.regionprops(nuc_labeled, intensity_image=nuc)  # Props for nuclear mask, nuc channel\n",
    "nuc_props_pH3 = measure.regionprops(nuc_labeled, intensity_image=pH3)  # Props for nuclear mask, pH3 channel\n",
    "nuc_props_act = measure.regionprops(nuc_labeled, intensity_image=act)  # Props for nuclear mask, act channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To better handle these, they can be transformed into dictionaries or pandas dataframes\n",
    "\n",
    "# Function to convert to dict\n",
    "def props2dict(props):\n",
    "        \n",
    "    # Get prop names (excluding non-scalar props!)\n",
    "    propdict = {prop_name:[] for prop_name in props[0]\n",
    "                if not (type(props[0][prop_name]) in [tuple, np.ndarray])}\n",
    "    \n",
    "    # For each prop name...\n",
    "    for prop_name in propdict:\n",
    "        \n",
    "        # For each region...\n",
    "        for region in props:\n",
    "            \n",
    "            # Add the corresponding value\n",
    "            propdict[prop_name].append(region[prop_name])\n",
    "        \n",
    "        # Convert the values to an array\n",
    "        propdict[prop_name] = np.array(propdict[prop_name])\n",
    "        \n",
    "    # Return results\n",
    "    return propdict\n",
    "\n",
    "\n",
    "# Converting nuc_props_pH3 and nuc_props_act to dicts\n",
    "propdict_pH3 = props2dict(nuc_props_pH3)\n",
    "propdict_act = props2dict(nuc_props_act)\n",
    "\n",
    "# Converting nuc_props_nuc to a pandas df\n",
    "propdf = pd.DataFrame(props2dict(nuc_props_nuc))\n",
    "propdf = propdf.drop(['bbox_area', 'euler_number'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Visualizing Region Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "propdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "propdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "propdf.boxplot()\n",
    "fig.autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Backmapping onto image\n",
    "color_prop = 'area'\n",
    "nuc_propcolored = np.zeros(nuc.shape)\n",
    "for row,label in enumerate(propdf.label):\n",
    "    nuc_propcolored[nuc_labeled==label] = propdict_act[color_prop][row]\n",
    "    \n",
    "# Show\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.imshow(act_bgsub, interpolation='none', cmap='gray')\n",
    "plt.imshow(np.ma.array(nuc_propcolored, mask=nuc_propcolored==0), \n",
    "           interpolation='none', cmap='plasma')\n",
    "plt.colorbar(label=color_prop, fraction=0.046, pad=0.04)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scatter plot to look at relations\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.scatter(propdf.area, propdf.perimeter, edgecolor='', alpha=0.5)\n",
    "plt.plot(np.sort(propdf.perimeter)**2.0 / (4*np.pi), np.sort(propdf.perimeter), color='r', alpha=0.8)\n",
    "plt.legend(['theoretical circles', 'data'], loc=4, fontsize=10)\n",
    "plt.xlabel('area')\n",
    "plt.ylabel('perimeter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Identifying Dividing Cells using a Support Vector Machine\n",
    "\n",
    "Based on the **pH3 channel**, cells currently undergoing mitosis can be identified without any ambiguity. However, if the **Hoechst channel** holds enough information on its own to confidently classify cells as mitotic and non-mitotic, the pH3 channel is no longer needed and its wavelength is freed up for other purposes.\n",
    "\n",
    "Here, we can use the pH3 channel to create a **ground truth** for the mitotic vs. non-mitotic classification. We can then use this to train a **support vector classifier** to identify mitotic cells without use of the pH3 channel.\n",
    "\n",
    "**<font color=red>Warning:</font> This is just a mock example!** Larger datasets will feature many cases that are less clear-cut than the ones observed here, so much **more data would be needed** to train a robust classifier. In particular, many more cases of mitotic cells would be needed so that a **balanced** training set can be constructed. Furthermore, because of the lack of data in this example, the classifier's performance is evaluated on the training set itself, which means that overfitting goes unnoticed. **In a real case, it is imperative to evaluate classifiers on separate training and test sets!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardizing the features to zero mean and unit variance\n",
    "propdf_stand = (propdf - propdf.mean()) / propdf.std()\n",
    "\n",
    "# Show\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "propdf_stand.boxplot()\n",
    "fig.autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use pH3 signal to create ground truth labels (True: \"in mitosis\" | False: \"not in mitosis\") \n",
    "\n",
    "# Check pH3 signal distribution with histogram\n",
    "plt.hist(propdict_pH3['mean_intensity'], bins=50)\n",
    "plt.ylim([0,20])\n",
    "plt.show()\n",
    "\n",
    "# Create ground truth\n",
    "ground_truth = propdict_pH3['mean_intensity'] > 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train Support Vector Classifier\n",
    "svc = svm.SVC()\n",
    "svc.fit(propdf_stand, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on the training data\n",
    "prediction = svc.predict(propdf_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate prediction with a confusion matrix\n",
    "cmat = metrics.confusion_matrix(ground_truth, prediction)\n",
    "\n",
    "# Show\n",
    "plt.imshow(cmat,interpolation='none',cmap='Blues')\n",
    "for (i, j), z in np.ndenumerate(cmat):\n",
    "    plt.text(j, i, z, ha='center', va='center')\n",
    "plt.xticks([0,1], [\"Non-Mitotic\",\"Mitotic\"])\n",
    "plt.yticks([0,1], [\"Non-Mitotic\",\"Mitotic\"], rotation=90)\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.ylabel(\"ground truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources for Further Study\n",
    "\n",
    "\n",
    "- **Online resource:** The [scikit-image docs](http://scikit-image.org/docs/0.13.x/) contain a lot of information, including a [user guide](http://scikit-image.org/docs/0.13.x/user_guide.html) and an extensive [gallery of examples](http://scikit-image.org/docs/0.13.x/auto_examples/index.html#examples-gallery).\n",
    "\n",
    "\n",
    "- **Online tutorial:** The materials from the EMBL Bio-IT Course [Python Workshop Image Processing](https://git.embl.de/grp-bio-it/python-workshop-image-processing) feature a self-explanatory tutorial pipeline.\n",
    "\n",
    "\n",
    "- **Free E-Book:** [BioImage Data Analysis](http://www.imaging-git.com/olympus-website-bioimage-data-analysis), a comprehensive introduction to BioImage Data Analysis with Fiji and MATLAB, by Kota Miura (former EMBL Center for Microscopy and Image Analysis).\n",
    "\n",
    "\n",
    "- **Online resource:** [OpenCV](http://docs.opencv.org/trunk/d1/dfb/intro.html) is a large library of image analysis algorithms that can be used with different programming languages. Tutorials on how to use OpenCV with Python can be found [here](http://docs.opencv.org/trunk/d6/d00/tutorial_py_root.html).\n",
    "\n",
    "\n",
    "- **Online resource:** The [SciPy Docs for scipy.ndimage](https://docs.scipy.org/doc/scipy/reference/tutorial/ndimage.html) provide a (brief and technical) overview of the ndimage module, which tends to be useful when working with higher-dimensional images and complements scikit-image quite well.\n",
    "\n",
    "\n",
    "- **Online resource:** [Mahotas](http://mahotas.readthedocs.io/en/latest/) is another python package for image analysis. It is largely redundant with scikit-image but built differently under the hood (with C++ instead of Cython), which can be advantageous in some cases.\n",
    "\n",
    "\n",
    "- **Online resource:** Python (or more accurately Jython) can also be used as a macro language in [ImageJ](http://imagej.net/Welcome)/[Fiji](http://fiji.sc/). An introduction can be found [here](http://imagej.net/Jython_Scripting), though I believe it is currently being rewritten and therefore a mess. The old version is [here](http://imagej.net/Jython_Scripting_Examples).\n",
    "\n",
    "\n",
    "- **<font color=green>Keep studying every week!</font> Join the [EMBL Coding Club!](https://bio-it.embl.de/coding-club/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Jason Moffat, Dorre A. Grueneberg, Xiaoping Yang, So Young Kim, Angela M. Kloepfer, Gregory Hinkle, Bruno Piqani, Thomas M. Eisenhaure, Biao Luo, Jennifer K. Grenier, Anne E. Carpenter, Shi Yin Foo, Sheila A. Stewart, Brent R. Stockwell, Nir Hacohen, William C. Hahn, Eric S. Lander, David M. Sabatini, David E. Root (2006): *A Lentiviral RNAi Library for Human and Mouse Genes Applied to an Arrayed Viral High-Content Screen*, Cell 124:6, 1283-1298."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
